{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#### Source: https://www.kaggle.com/c/avazu-ctr-prediction\n",
    "# Load Data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# small functions for converting 'hour'\n",
    "def convert_hour(s):\n",
    "    string = str(s)\n",
    "    h = string[6:8]\n",
    "    return h \n",
    "\n",
    "def convert_weekday(s):\n",
    "    string = str(s)\n",
    "    yyyy = int('20'+string[:2])\n",
    "    mm = int(string[2:4])\n",
    "    dd = int(string[4:6])\n",
    "    weekday = datetime.date(yyyy,mm,dd).weekday()\n",
    "    return weekday\n",
    "\n",
    "\n",
    "\n",
    "# convert 'hour' in train to weekday and hour\n",
    "test['weekday'] = test['hour'].apply(convert_weekday)\n",
    "test['h'] = test['hour'].apply(convert_hour)\n",
    "train['weekday'] = train['hour'].apply(convert_weekday)\n",
    "train['h'] = train['hour'].apply(convert_hour)\n",
    "a = test['weekday'].value_counts()\n",
    "\n",
    "# use only the weekday in test.csv as training samples , a big and risky assumption \n",
    "Sample_train = train[train['weekday'].isin(a.index)]\n",
    "test_new = test\n",
    "\n",
    "# save these new table so that I do not need to load the source file everytime\n",
    "Sample_train.to_csv('Submission_table.csv', sep=',', encoding='utf-8',index = False)\n",
    "test_new.to_csv('test_new.csv', sep=',', encoding='utf-8',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading point 1 \n",
    "Sample_train = pd.read_csv('Submission_table.csv')\n",
    "test_new = pd.read_csv('test_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use only a subset of training samples\n",
    "# Since there is only one day in both training and test data, so discard this column\n",
    "test_new = test_new.drop(columns=['weekday'])\n",
    "Sample_train = Sample_train.drop(columns=['weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filed (feature) selection (based on heuristics and the neeed to simplify the model )\n",
    "## drop some columns and make the remaining columns categorical\n",
    "Sample_train = Sample_train.drop(columns=['id','hour','site_id',\n",
    "                            'site_domain','app_id','app_domain','device_model','device_id','device_ip','C14','C17'])\n",
    "# drop id, the primary key\n",
    "# drop hour, it has been converted\n",
    "# drop site_id, since site_category carries better info, and too many features in it\n",
    "# drop site_domain, less irrelevant, too many features in it\n",
    "# drop app_id and app_domain for similar reasons\n",
    "# device_ip should carry useful information, however I am not very sure how to go about it right now.\n",
    "# kernel keeps dying, so drop device_model too\n",
    "# drop some anonymous colmns, C14 and C17, too many features\n",
    "\n",
    "test_new = test_new.drop(columns=['id','hour','site_id',\n",
    "                               'site_domain','app_id','app_domain','device_model','device_id','device_ip','C14','C17'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test is very big, its processing killed the kernel, decided to use only 10%\n",
    "\n",
    "Sample_test = test_new.sample(int(np.round(0.1*test_new.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the label column form the training data\n",
    "Sample_train_label = Sample_train['click']\n",
    "Sample_train = Sample_train.drop(columns=['click'])\n",
    "\n",
    "Sample_train_label.to_csv('Sample_train_label.csv',sep=',', encoding='utf-8',index = False)\n",
    "Sample_train.to_csv('Sample_train.csv',sep=',', encoding='utf-8',index = False)\n",
    "#Sample_test.to_csv('Sample_test.csv',sep=',', encoding='utf-8',index = False)\n",
    "\n",
    "######## Load point 2 ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "580806"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suspect = Sample['device_id'] == 'a99f214a'\n",
    "Sample[suspect]['click'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data type to categorical, easier for creating dummies\n",
    "for i in Sample_train.columns:\n",
    "    Sample_train[i] = Sample_train[i].astype('category')\n",
    "    \n",
    "for j in Sample_test.columns:\n",
    "    Sample_test[j] = Sample_test[j].astype('category')\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing dummy variables for Logistic Regression and Factorization Machine\n",
    "Sample_train_dummy = pd.DataFrame()\n",
    "for i in Sample_train.columns:\n",
    "    dummy = pd.get_dummies(Sample_train[i], prefix = i)\n",
    "    Sample_train_dummy = pd.concat([Sample_train_dummy,dummy], axis=1)\n",
    "    #368 dummies\n",
    "Sample_test_dummy = pd.DataFrame()\n",
    "for j in Sample_test.columns:\n",
    "    dummy = pd.get_dummies(Sample_test[j], prefix = j)\n",
    "    Sample_test_dummy = pd.concat([Sample_test_dummy,dummy], axis=1)\n",
    "    #352 dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the features that are in test set but not in training set\n",
    "inTestnotinTrain = Sample_test_dummy.columns[~Sample_test_dummy.columns.isin(Sample_train_dummy.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the features that are in training set but not in test set\n",
    "inTrainnotinTest = Sample_train_dummy.columns[~Sample_train_dummy.columns.isin(Sample_test_dummy.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both Training data and test data have the same predictors\n",
    "for i in inTrainnotinTest:\n",
    "    Sample_test_dummy[i] = 0\n",
    "    \n",
    "for j in inTestnotinTrain:\n",
    "    Sample_train_dummy[j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "######### Base Line Model ##########################\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#log-loss evaluation, becasue the predictions are probabilities\n",
    "LR1 = LogisticRegression(penalty ='l1',solver = 'saga')\n",
    "scores = cross_val_score(LR1, Sample_train_dummy, Sample_train_label, cv=5, scoring = 'neg_log_loss')\n",
    "scoresLR1 = -1*scores \n",
    "\n",
    "LR2 = LogisticRegression(penalty ='l2',solver = 'saga')\n",
    "scores = cross_val_score(LR2, Sample_train_dummy, Sample_train_label, cv=5, scoring = 'neg_log_loss')\n",
    "scoresLR2 = -1*scores \n",
    "\n",
    "##### The other possible models for classification problems #########\n",
    "# 1. Support Vector Machine: Here the matrix is very sparce(many zero entries), SVM is not ideal\n",
    "# 2. Tree-Based methods, eg Random Foreset, here the dimentionality is high (due to 100% categorical features), \n",
    "#   Random Forest is computationally more expensive, and prone to overfit (complicated models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45476720520289576\n",
      "0.45516997561531103\n"
     ]
    }
   ],
   "source": [
    "print(sum(scoresLR1)/5) # log-loss of logistic regression with L1 penalty\n",
    "print(sum(scoresLR2)/5) # log-loss of logistic regression with L2 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Factorization Machine #####################\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "#Sample_train_dummy.reset_index(drop = True)\n",
    "#Sample_train_label.reset_index(drop = True)\n",
    "def FM_CV(KFold, FM, X,y):\n",
    "    l = []\n",
    "    for train, test in KFold.split(X, y):\n",
    "        # Start to train\n",
    "        FM.fit(X.iloc[train], y.iloc[train]) \n",
    "        y_pred = FM.predict(X.iloc[test])\n",
    "        loss = log_loss(y.iloc[test], y_pred, eps=1e-15)\n",
    "        l.append(loss)\n",
    "        score = sum(l)/len(l)\n",
    "        return score\n",
    "    \n",
    "kf = KFold(n_splits=5)\n",
    "#kf.get_n_splits(Sample_train_dummy)\n",
    "# param:\n",
    "#  0. binary classification\n",
    "#  1. model scale: 0.1\n",
    "#  2. epoch number: 10 (auto early-stop)\n",
    "#  3. number of latent factor: 4\n",
    "#  4. learning rate: 0.1\n",
    "#  5. regular lambda: 0.01\n",
    "#  6. use sgd optimization method\n",
    "#  7. evaluation metric: accuarcy\n",
    "\n",
    "# hyperparameter k\n",
    "K_vector = [2,3,4,5,6,7,8,9,10]\n",
    "FM_score = []\n",
    "for i in K_vector: \n",
    "    fm_model = xl.FMModel(task='binary', init=0.1, \n",
    "                      epoch=10, k=i, lr=0.15, \n",
    "                      reg_lambda=0.01, opt='sgd', \n",
    "                      metric='acc')\n",
    "\n",
    "    score = FM_CV(kf, fm_model, Sample_train_dummy,Sample_train_label)\n",
    "    FM_score.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4912672512911138,\n",
       " 0.4669381348344845,\n",
       " 0.4498570274823115,\n",
       " 0.45737060188033274,\n",
       " 0.45328016991364184,\n",
       " 0.4547271786191499,\n",
       " 0.45139659328669973,\n",
       " 0.45419716577430996,\n",
       " 0.45031769235750124]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FM_score # FM model, k =4, average log-loss 0.4499, being the best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Field-Aware Factorization Machine\n",
    "# Dictionary of the fields, for converting DataFrame to Libffm format\n",
    "Fields = {}\n",
    "j=0\n",
    "for i in Sample_train.columns:\n",
    "    Fields[i] = j\n",
    "    j = j + 1\n",
    "# Get the union of features\n",
    "Joint = pd.concat([Sample_train, Sample_test],axis=0)\n",
    "Joint = Joint.astype('str')\n",
    "\n",
    "# Dictionaries of the features for each field\n",
    "for i in Fields:\n",
    "    dictionary = i\n",
    "    Features = Joint[i].value_counts().index\n",
    "    exec('%s = {}' %dictionary)\n",
    "    c = 0\n",
    "    for j in Features:\n",
    "        exec('%s[j] = c' %dictionary)\n",
    "        c = c + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Libfmm format for trianing data\n",
    "\n",
    "import os\n",
    "filename = 'Sample_train.txt'\n",
    "file = open(filename, 'w') #truncate first\n",
    "for i in range(0,Sample_train.shape[0]):\n",
    "    Clause = str(Sample_train_label.iloc[i]) + ' ' # first entry should be the label\n",
    "    \n",
    "    for j in Fields:\n",
    "        field = j\n",
    "        field_index = Fields[j]\n",
    "        feature = Sample_train[j].iloc[i]\n",
    "        exec(\"feature_index = %s['%s']\"% (field, feature))\n",
    "        sub_clause = '%s:%s:1' %(field_index ,feature_index)\n",
    "        Clause = Clause + sub_clause + ' '\n",
    "        \n",
    "    file.write(Clause)\n",
    "    file.write('\\n')\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ffm - cross validation\n",
    "# k = 2\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':2}\n",
    "\n",
    "ffm_model.cv(param)\n",
    "#------------] Average log_loss: 0.550212\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 147.73 (sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 3\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':3}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.500893\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 146.65 (sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 4\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':4}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.493209\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 146.67 (sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 5\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':5}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.486877\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 200.83 (sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 6\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':6}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.485178\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 200.60 (sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 7\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':7}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.466884\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 208.30 (sec)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 8\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain('Sample_train.txt')\n",
    "param = {'task':'binary', 'lr':0.15, 'lambda':0.002, 'opt':'sgd','epoch':10,'k':8}\n",
    "ffm_model.cv(param)\n",
    "#[------------] Average log_loss: 0.523609\n",
    "#[ ACTION     ] Finish Cross-Validation\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 204.80 (sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Libffm format for test data\n",
    "filename = 'Sample_test.txt'\n",
    "file = open(filename, 'w') #truncate first\n",
    "for i in range(0,Sample_test.shape[0]):\n",
    "    Clause = str() \n",
    "    \n",
    "    for j in Fields:\n",
    "        field = j\n",
    "        field_index = Fields[j]\n",
    "        feature = Sample_train[j].iloc[i]\n",
    "        exec(\"feature_index = %s['%s']\"% (field, feature))\n",
    "        sub_clause = '%s:%s:1' %(field_index ,feature_index)\n",
    "        Clause = Clause + sub_clause + ' '\n",
    "        \n",
    "    file.write(Clause)\n",
    "    file.write('\\n')\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Summary ######\n",
    "# FM performs only slightly better than the base line model (LR), and it should remain inconclusive.\n",
    "# FFM shows no adventage here, possibily because the current model (fields and features) are too simplified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predict with the best model from cross validation\n",
    "# Factorization Machine with k = 4\n",
    "fm_model = xl.FMModel(task='binary', init=0.1, \n",
    "                     epoch=10, k=4, lr=0.15, \n",
    "                      reg_lambda=0.01, opt='sgd', \n",
    "                      metric='acc')\n",
    "\n",
    "fm_model.fit(Sample_train_dummy, Sample_train_label)\n",
    "\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = fm_model.predict(Sample_test_dummy)\n",
    "#[------------] Loss function: cross-entropy\n",
    "#[------------] Score function: fm\n",
    "#[------------] Number of Feature: 368\n",
    "#[------------] Number of K: 4\n",
    "#[------------] Time cost for loading model: 0.00 (sec)\n",
    "#[ ACTION     ] Read Problem ...\n",
    "#[------------] First check if the text file has been already converted to binary format.\n",
    "#[------------] Binary file (/var/folders/cp/rtwd28t94wz4spwfb2c8bqpm0000gn/T/tmpjlau0e2j.bin) NOT found. Convert text file to binary file.\n",
    "#[------------] Time cost for reading problem: 1.36 (sec)\n",
    "#[ ACTION     ] Start to predict ...\n",
    "#[------------] The test loss is: 0.091477  <----- This doesn't make sense, since there is no label in the test data\n",
    "#[ ACTION     ] Clear the xLearn environment ...\n",
    "#[------------] Total time cost: 1.68 (sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0271347 0.0318787 0.0417414 ... 0.274749  0.0438931 0.0448321] (457746,)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
